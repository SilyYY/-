# 绪论

<h3 style="color:blue">机器学习本质</h3>

>已知一组数据，在这组数据上通过算法学习到一种模型。

- **样本**：用来反映对象在某方面的表现或性质的事项
- **数据集**：由多个样本构成的
- **输入空间**：对象所有属性张成的空间
- **泛化能力**：学得模型适应新样本的能力
<h3 style="color:blue">机器学习分为两类</h3>

> 监督学习：分类和回归，分别为预测离散和连续值。
> 无监督学习：聚类。

<h3 style="color:blue">假设空间</h3>

- 推理的两大基本手段：归纳和推理。

> 归纳:从特殊到一般的泛化过程。
> 演绎：从一般到特殊的特化过程。

机器学习就是从训练数据中学习，进行合理的归纳偏好，从假设空间中学习得到最合理的假设。
**假设空间指的是问题所有假设组成的空间，我们可以把学习过程看作是在假设空间中搜索的过程，搜索目标是寻找与训练集“匹配”的假设。**

----

# 模型评估和误差

<h3 style="color:blue">经验误差和过拟合</h3>

### 基本概念
- 训练误差：学习器在训练集上的误差
- 泛化误差：学习器在新样本上的误差
- 过误拟合和欠拟合：对样本学习的过度与不及。

<h3 style="color:blue">评估方法</h3>

需要一个尽可能与训练集互斥的测试集，用该测试集来测试学习器对新样本的判别能力，以测试集上的“测试误差”作为泛化误差的近似。

<p style="color:#EEEE00">给出一个包含n个样本的数据集，划分训练集和测试集的方法</p>

> 留出法
> > 直接将数据集D划分为两个互斥的集合。注意要分层采样，尽可能保持数据分布的一致，训练集太小与D差别太大，训练集太大的话，测试集就太小了，评估结果不够稳定准确，**所以常见的方法是2/3~4/5的样本用于训练**。
>
>交叉验证法
>>将数据集D划分为k个大小相似的互斥子集。每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，最终返回这k个测试结果的均值，即k折交叉验证。另k=样本数m，则只有唯一的方式划分为m个子集，**留一法虽然比较准确但是数据集太大的时候计算开销难以忍受**。
>
>自助法
>>每次随机从D中挑选一个样本，将其拷贝放入D'，然后再放回数据集D中，使其下一次扔可能被采到，进行m次，（1-1/m）的m次方，当m趋近于无穷大，结果为0.368，**因此初始样本集约有36.8%的样本没在训练集里，这样的测试结果称为包外估计**。


### 调参与最终模型
**学习算法和参数配置已选定，此时应该用数据集D重新训练模型，这个模型在训练过程中使用了所有m个样本，这才是我们最终提交给用户的模型。**
<h3 style="color:blue">性能度量</h3>

